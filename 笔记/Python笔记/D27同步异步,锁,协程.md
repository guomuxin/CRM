# D27同步异步,锁,协程

## 一、线程同步

- 需要进行线程同步的原因:多个线程同时修改同一个数据时,有可能会出现意想不到的错误,这是因为调度程序有可能在一次操作并没有执行完毕时就将其调出cpu,为了防止这种情况的发生,就要通过线程同步保证每个线程的动作都能一次性执行完毕,保证线程的原子性

- 原子性:一段代码,要么都执行,要么都不执行

- 线程同步的方式:互斥锁

- 互斥锁:为资源引入一个状态:锁定/非锁定,每当有线程在对资源进行修改,就将资源的状态修改为锁定,其他线程就不能修改该资源,直到修改它的线程操作完毕,释放资源,将资源的状态修改为非锁定,别的线程再去竞争该锁,再次锁定该资源.互斥锁保证每次只有一个线程在进行写入操作,从而保证了多线程情况下数据的正确性

  - 使用方法:threading模块中的Lock类
    - 创建锁:mutex = threading.Lock()
    - 锁定:mutex.acquire()
    - 释放:mutex.release()

  ```
  导包,定义函数:
  import threading,time
  num = 0
  def f1():
      global num
      mutexA.acquire()			#上锁,当其他线程企图获取该锁时就陷入同步阻塞状态
      for i in range(1000000):
          num += 1
      mutexB.acquire()
      print(t1.name)
      print("f1",num)
      mutexA.release()			#释放
  
  def f2():
      global num
      mutexA.acquire()
      print(t1.name)
      for i in range(1000000):
          num += 1
      print("f2",num)
      mutexA.release()
  
  ```

  ```
  定义锁,创建线程:
  if __name__ == '__main__':
      mutexA = threading.Lock()
  
      t1 = threading.Thread(target=f1)
      t2 = threading.Thread(target=f2)
  
  
      t1.start()
      t2.start()
  
      print(num)
  ```
  - 死锁:在线程共享多个资源的时候,两个线程各占有部分资源且在互相等待对方的资源就会造成死锁

  ```
  了解即可,错误示范:
  import threading,time
  num = 0
  def f1():
      global num
      mutexA.acquire()
      for i in range(1000000):
          num += 1
      mutexB.acquire()
      print(t1.name)
      print("f1",num)
      mutexA.release()
      mutexB.release()
  def f2():
      global num
      mutexB.acquire()
      print(t1.name)
      for i in range(1000000):
          num += 1
      mutexA.acquire()
      print("f2",num)
      mutexB.release()
      mutexA.release()
  
  if __name__ == '__main__':
      mutexA = threading.Lock()
      mutexB = threading.Lock()
  
      t1 = threading.Thread(target=f1)
      t2 = threading.Thread(target=f2)
  
  
      t1.start()
      t2.start()
  
      time.sleep(1)
      print(num)
  ```

- 信号量(Semaphore):用于控制同一时间进入线程数量的锁,控制线程并发数的

  - 例如在读写操作时,如果同时有过多线程进行读操作有可能会导致程序卡顿或崩溃,这时就可以通过信号量控制同时读取文件的数量(如果使用互斥锁同时只能有一个线程读)

  - 使用方法:se = threading.Semaphore():参数规定同时最多可以有几个线程

  - ```
    import threading
    import time
    def func(n):
        se.acquire()
        for i in range(100):
            print("线程",n,  i)
            time.sleep(1)
        se.release()
    
    if __name__ == '__main__':
        se = threading.Semaphore(3)
        for i in range(10):
            t = threading.Thread(target=func,args=(i,))
            t.start()
    输出结果:
    三个一组打印(由于都是休眠1秒,所以同时打印三个)
    ```

- Python的Queue模块提供了三种类型的队列来实现线程同步

  - FIFO队列Queue:先进先出查找

  - LIFO栈LifoQueue:先进后出查找

  - 优先级队列PriorityQueue:条目被保存为有序的（使用heapq模块）并且最小值的条目被最先检索

  - 这些队列都实现了锁原语(即原子操作),能够在多线程中直接使用

  - 消息队列:queue模块中的Queue对象

    q = Queue(maxsize=):maxsize代表可以容纳的对象最大数量,如果为0或为负会不限定大小

    ```
    FIFO队列应用(生产者消费者模型):
    生产者就是用于生产数据的线程,消费者就是消费数据的线程,如果直接将消费者和生产者关联,耦合性太高,并且可能会有生产数据速度远大于消费数据速度,或者消费速度远大于生产速度,就会出现问题
    生产者和消费者彼此不直接通信,而是同过消息队列间接通信
    ```

    ```
    生产者:
    from queue import Queue
    import threading
    import time
    class Pro(threading.Thread):
        def run(self):
            global q
            while True:
                if q.qsize() < 1000:
                    for i in range(100):
                        msg = "生产品" + str(i)
                        q.put(msg)
                        print("生产",msg)
                    time.sleep(1)
    ```

    ```
    消费者:
    class Con(threading.Thread):
        def run(self):
            global q
            while True:
                if q.qsize() > 100:
                    for i in range(100):
                        msg = q.get()
                        print("获取",msg)
                    time.sleep(1)
    ```

    ```
    使用:
    if __name__ == '__main__':
        q = Queue()
        t_Pro = Pro()
        t_Con = Con()
    
        t_Pro.start()
        t_Con.start()
    
    ```

    

- GIL全局解释器锁:Cpython独有的锁,牺牲效率保证数据安全

  - GIL是一把双刃剑,带来优势的同时也带来一些问题

  - Python文件的执行顺序:

    - 操作系统将应用程序从硬盘加载到内存,运行Python文件,在内存中开辟一块空间,将Python解释器以及py文件加载进去,解释器运行py文件
    - Python解释器分为两部分,先将代码通过编译器编译成C的字节码,然后你的虚拟机拿到你的C的字节码,输出机器码,再配合操作系统把你的机器码扔给CPU去运行
    - 你的py文件有一个主线程,主线程做的就是这个过程,如果开多线程,每个线程的都要进行这个过程

  - 理想的情况：

    - 三个线程，得到三个机器码，然后交由CPU，三个线程同时扔给三个CPU，然后同时进行，最大限度的提高效率，但是CPython多线程应用不了多核

    - CPython到底干了一件什么事情导致用不了多核？

    - Cpython在所有线程进入解释器之前加了一个全局解释器锁（GIL锁）。这个锁是互斥锁，是加在解释器上的，导致同一时间只有一个线程在执行所以你用不了多核

  - 为什么这么干？
    - 之前写python的人只有一个cpu。。。
    - 所以加了一个锁，保证了数据的安全，而且在写python解释器时，更加好写了

  - 为什么不取消这个锁？

    - 解释器内部的管理全部是针对单线程写的

  - 能不能不用Cpython？

    - 官方推荐Cpython，处理速度快，相对其他解释器较完善。其他解释器比如pypy规则和漏洞很多

  - 那我该怎么办？

    - 虽然多线程无法应用多核，但是多进程可以应用多核（开销大）

  - Python已经有一个GIL来保证同一时间只能有一个线程来执行了，为什么我还要学互斥锁? 

    - 首先我们需要达成共识：锁的目的是为了保护共享的数据，同一时间只能有一个线程来修改共享的数据

    - 然后，我们可以得出结论：保护不同的数据就应该加不同的锁。

    - 所以，GIL 与Lock是两把锁，保护的数据不一样，前者是解释器级别的（当然保护的就是解释器级别的数据，比如垃圾回收的数据），后者是保护用户自己开发的应用程序的数据，很明显GIL不负责这件事，只能用户自定义加锁处理

## 二、 同步异步

- 什么是同步调用:确定调用的顺序,提交一个任务,必须等到这个任务结束才会开启下一个任务

  - 同步意味着顺序,统一的时间轴,和串行区别不太大

  - 使用场景1:执行第一个事务阻塞了,会一直等待直到完成,再执行第二个事务,按照预定的先后顺序执行

  - 使用场景2:一个任务的执行依赖于另一个任务,所以必须等待另一个任务执行完毕再开启

  - ```
    import threading
    import time
    def func1():
        while True:
            mutex1.acquire()
            print("func111")
            time.sleep(1)
            mutex2.release()
    
    def func2():
        while True:
            mutex2.acquire()
            print("func222")
            time.sleep(1)
            mutex3.release()
    
    def func3():
        while True:
            mutex3.acquire()
            print("func333")
            time.sleep(1)
            mutex1.release()
    
    if __name__ == '__main__':
        mutex1 = threading.Lock()
        mutex2 = threading.Lock()
        mutex2.acquire()
        mutex3 = threading.Lock()
        mutex3.acquire()
        t1 = threading.Thread(target=func1)
        t2 = threading.Thread(target=func2)
        t3 = threading.Thread(target=func3)
        t1.start()
        t2.start()
        t3.start()
      执行顺序永远是:func1,func2,func3
    ```

- 什么是异步调用:不确定调用顺序,一次提交多个任务,然后就继续往下执行

  -  调用这个事务之后,不等待它的执行结果,直接开始执行后面的事务,通过状态或者回调通知调用者处理结果

  - 对于IO操作来说,异步可以大幅度提示系统吞吐量,因为在进行读写操作时,系统可以去处理其他操作

  - 异步的实现方式:

    - 正常写的多线程都是异步的

    - 通过循环控制(太low,不用)

    - 通过回调机制:回调就是将每个函数的执行结果return给回调函数,由回调函数统一处理

      ```
      定义函数:
      from multiprocessing import Pool,Lock
      lock = Lock()
      def funcA(n):
          for i in range(10):
              print(f"线程{n}读取文件{i}")
          return "完成"
      def funcB(n):
          for i in range(10):
              print(f"线程{n}读取文件{i}")
          return "完成"
      def funcC(n):
          for i in range(10):
              print(f"线程{n}读取文件{i}")
          return "完成"
      
      
      回调函数:
      def alter(msg):
          print(msg)
      
      ```

      ```
      使用:
      
      if __name__ == '__main__':
          po = Pool(3)
          po.apply_async(func=funcA, args=(1,), callback=alter)
          po.apply_async(func=funcB, args=(2,), callback=alter)
          po.apply_async(func=funcC, args=(3,), callback=alter)  #callback参数															就是回调函数的函																数名
      
          po.close()
          po.join()
      
      ```

      三个func将都返回一个执行结果,由于设定了callback,会自动将return的值传给回调函数当参数,回调函数再进行下一步处理

## 三、协程

- 协程:比线程更小的执行单位,一个线程作为一个容器可以放置多个协程

- 作用:只切换函数调用即可完成多线程,普通线程工作时会在不固定的某个时刻切换cpu,而协程是是自己主动切换,这样就减少了切换次数,协程通过函数调用即可完成多任务

- 协程自己主动让出cpu

- 协程需要导入greenlet模块中的greenlet类

- 协程使用:使用协程对象.switch()切换至该协程

  ```
  from greenlet import greenlet
  
  
  def fA():
      while True:
          print("A")
          g2.switch()
  
  def fB():
      while True:
          print("B")
          g3.switch()
  
  def fC():
      while True:
          print("C")
          g1.switch()
  g1 = greenlet(fA)
  g2 = greenlet(fB)
  g3 = greenlet(fC)
  g1.switch()
  输出结果:
  A
  B
  C
  ...
  ```

- gevent:比greenlet更加强大, 当遇到IO操作时,自动切换至其他协程,IO完成后再选择适当时机切回来继续执行

  - gevent只有在遇到自己认识的IO操作时才会切换
  - 需要注意的地方:
    - gevent创建对象的方法是:gevent.spawn()
    - 结尾需要全部join
    - sleep需要gevent.sleep

  